[
  {
    "objectID": "dataviz.html",
    "href": "dataviz.html",
    "title": "Data Viz",
    "section": "",
    "text": "Visuals created from TidyTuesday data and mini projects are on this page. Feel free to look around :)",
    "crumbs": [
      "Data Viz"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Veronica De Leon",
    "section": "",
    "text": "Hi! I’m Veronica (she/her) and welcome to my website. I love math and am currently getting into data science. More about me and my site on the ‘About’ page."
  },
  {
    "objectID": "tidytues2.html",
    "href": "tidytues2.html",
    "title": "Chocolate Rating",
    "section": "",
    "text": "The link to the original data is here\n\n\nShow the code\nlibrary(ggplot2)\nlibrary(\"tidytuesdayR\")\nlibrary(dplyr)\ntuesdata &lt;- tidytuesdayR::tt_load('2022-01-18')\n\n\n\n\nShow the code\nchocolates &lt;- tuesdata$chocolate |&gt;\n  select(cocoa_percent, rating) |&gt;\n  group_by(cocoa_percent) |&gt;\n  summarize(avg_rating = mean(rating), na.rm = TRUE) |&gt;\n  \n  filter(cocoa_percent &gt;= \"75%\")\n\nchocolates\n\n\n# A tibble: 18 × 3\n   cocoa_percent avg_rating na.rm\n   &lt;chr&gt;              &lt;dbl&gt; &lt;lgl&gt;\n 1 75%                 3.17 TRUE \n 2 76%                 3.02 TRUE \n 3 77%                 3.08 TRUE \n 4 78%                 3.38 TRUE \n 5 79%                 3.25 TRUE \n 6 80%                 3.08 TRUE \n 7 81%                 2.92 TRUE \n 8 82%                 3.04 TRUE \n 9 83%                 3    TRUE \n10 84%                 2.81 TRUE \n11 85%                 3    TRUE \n12 86%                 3.25 TRUE \n13 87%                 3.25 TRUE \n14 88%                 3.22 TRUE \n15 89%                 2.62 TRUE \n16 90%                 2.97 TRUE \n17 91%                 2.17 TRUE \n18 99%                 2.62 TRUE \n\n\n\n\nShow the code\nchocolates |&gt;\n  ggplot(aes(cocoa_percent, avg_rating)) +\n  geom_point(color = \"brown\", alpha = 0.5, size = 3) +\n  labs(\n    x = \"Cocoa Percent\",\n    y = \"Average Chocolate Rating\", \n    title = \"Chocolate Rating by Cocoa Percent\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "Chocolate Rating"
    ]
  },
  {
    "objectID": "tidytues1.html",
    "href": "tidytues1.html",
    "title": "Carbon Majors Emissions",
    "section": "",
    "text": "The link to the original data is here\n\n\nShow the code\nlibrary(ggplot2)\nlibrary(\"tidytuesdayR\")\nlibrary(dplyr)\ntuesdata &lt;- tidytuesdayR::tt_load('2024-05-21')\n\n\n\n\nShow the code\nemit_co2 &lt;- tuesdata$emissions\nggplot(emit_co2, aes(x = year, y = total_emissions_MtCO2e, color = commodity)) +\n  geom_point(alpha = 0.2) +\n  facet_wrap(~ commodity) +\n  labs(\n    x = \"Year\",\n    y = \"Total CO2 Emissions\",\n    title = \"Total Emissions per Commodity per Year\",\n    color = \"Commodity\"\n  ) +\n  theme_minimal ()",
    "crumbs": [
      "Carbon Majors Emissions"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Veronica De Leon",
    "section": "",
    "text": "About Author\nI was born in the Philippines but I’ve been living in Los Angeles since I was nine (the building pictured is in Downtown LA). I’m currently studying at Pomona College for mathematics and statistics. I love crafting, specifically knitting and sewing (the image on my home page is a design that I sewed onto a shirt).\n\n\nAbout this site\nThis site currently contains projects for my Foundations of Data Science DS002 class."
  },
  {
    "objectID": "miniproj_2.html",
    "href": "miniproj_2.html",
    "title": "Text Analysis",
    "section": "",
    "text": "Show the code\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(stringr)\n\n\nThe link to Netflix data is here\n\n\nShow the code\nnetflix &lt;- read.csv(\"../veronica-2222.github.io/netflix_titles.csv\")\n\n\n\nGeneral Netflix Data\n\n\nShow the code\nnetflix |&gt;\n  select(release_year, date_added) |&gt;\n  mutate(added_year = str_extract(date_added, \"(?&lt;=, ).+(?=$)\")) |&gt;\n  filter(!is.na(release_year), !is.na(added_year)) |&gt;\n  ggplot(aes(x = release_year, y = added_year)) +\n  geom_point(alpha = 0.3) +\n  labs(\n    x = \"Year Show/Movie was Released\",\n    y = \"Year Show/Movie was Added\",\n    title = \"Analysis of Year Show/Movie was Released\\n\\ versus Year Added on Netflix\"\n  ) +\ntheme_minimal()\n\n\n\n\n\n\n\n\n\nThe graph displays the difference between the year a show or movie was released versus the year it was added on Netflix. The opaqueness of the points suggests when majority of the shows and movies were added on Netflix. In this case it seems as if majority of the shows and movies were added in 2016 and onward.\n\n\nShow the code\nnetflix|&gt;\n  select(rating, listed_in) |&gt;\n  mutate(tv_rating = str_extract(rating, \"(?&lt;=-).+(?=$)\")) |&gt;\n  mutate(first_listed = str_extract(listed_in, \"\\\\w+\")) |&gt;\n  filter(first_listed %in% c(\"Action\", \"Crime\", \"Dramas\", \"Comedies\")) |&gt;\n  filter(tv_rating %in% c(\"13\", \"14\", \"G\", \"PG\", \"MA\")) |&gt;\n  mutate (level_rating = fct_relevel(tv_rating, c(\"13\", \"14\", \"G\", \"PG\", \"MA\"))) |&gt;\n  ggplot(aes(x = level_rating, fill = first_listed)) +\n  geom_bar(position = \"fill\") +\n  labs(\n    title = \"Number of Specific TV Ratings\",\n    subtitle = \"Categorized by Genres\",\n    x = \"TV-__\",\n    y = \"Proportion of Shows\",\n    fill = \"Genre\",\n  ) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nThe bar reveals the proportion of shows’ first genre they are listed under and their TV-rating. It can reveal which genres were mostly rated TV-14, PG, etc. For example, one of the major points this bar reveals is that majority of the TV-show rated as G are Dramas. The lack of blue suggests that there are few TV shows that have ‘Crime’ as the first genre they are listed under. And many of the TV-14 and PG shows are listed under ‘Comedies’ and ‘Dramas’.\n\n\n\n\n\nNarrowed Netflix Data\n\nComedies and Christmas Eve\n\n\nShow the code\nnetflix |&gt;\n  select(type, duration, title, date_added, listed_in) |&gt;\n  group_by(type) |&gt;\n  filter(str_detect(type, \"TV Show\")) |&gt;\n  filter(str_detect(date_added , \"2021\")) |&gt;\n  filter(str_detect(listed_in, \"Comedies\")) |&gt;\n  mutate(season = str_sub(duration, 1, 1)) |&gt; \n  summarize(type, title, season) |&gt;\n  ggplot(aes(y = season)) +\n  geom_bar() +\n  labs(\n    title = \"Season and Show Count of Comedy TV Shows Added \\n\\ on Netflix in 2021\",\n    x = \"Number of Shows\",\n    y = \"Number of Seasons\"\n  ) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nThe bar graph reveals the frequency of comedy shows added on Netflix in 2021 to have a certain number of seasons. It is evident that majority of the comedy shows only have 1 season.\n\n\nShow the code\nChristmas_eve &lt;- netflix |&gt;\n  select(title, type, date_added, listed_in) |&gt;\n  mutate(first_listed = str_extract(listed_in, \"\\\\w+\")) |&gt;\n  mutate(Title_Type=  str_c(title, type, first_listed, sep=': ')) |&gt;\n  mutate(Date = str_extract(date_added, \".+(?=,)\")) |&gt;\n  mutate(Genre = listed_in) |&gt;\n  filter(Date == \"December 24\"| Genre == \"TV\")|&gt;\n    select(Title_Type, Date) \n\nas_tibble(Christmas_eve)\n\n\n# A tibble: 9 × 2\n  Title_Type                                           Date       \n  &lt;chr&gt;                                                &lt;chr&gt;      \n1 Bridezilla: Movie: Comedies                          December 24\n2 Cemara's Family: Movie: Children                     December 24\n3 Hello, Love, Goodbye: Movie: Dramas                  December 24\n4 CAROLE & TUESDAY: TV Show: Anime                     December 24\n5 Como caído del cielo: Movie: Comedies                December 24\n6 John Mulaney & The Sack Lunch Bunch: Movie: Children December 24\n7 Lost in Space: TV Show: TV                           December 24\n8 Stand Up and Away! with Brian Regan: TV Show: Stand  December 24\n9 Way Back into Love: TV Show: International           December 24\n\n\nThe table classifies the titles added on Netflix on December 24 (with varying years) with their type (TV Show or Movie) and the first genre they are listed under.",
    "crumbs": [
      "Text Analysis"
    ]
  },
  {
    "objectID": "miniproj_3.html",
    "href": "miniproj_3.html",
    "title": "A Simulation Study",
    "section": "",
    "text": "Show the code\nlibrary(openintro)\nlibrary(tidyverse)\nlibrary(stringr)\n\n\n\nAbout the Data\nThe link to the original data is here\nFor this project, I used the ‘Dream’ data set from the openintro package. The data set came from SurveyUSA, News Poll and was collected on January 27-29, 2012. The poll surveyed the views of 910 people on the DREAM Act (a legislative proposed to give undocumented immigrants temporary residency so that they could work in the US). Those surveyed were categorized into three ideologies: Liberal, Moderate, and Conservative. Their responses were either No, Not Sure, or Yes.\n\n\nAbout the Simulation\nFrom the observed data of the data set, I noticed that the proportion of Liberals in support of the Dream Act (0.65) is greater than the proportion of Conservatives (0.5) and the proportion of Moderates (0.48). So, I set to test if there is truly a relationship between ideology and whether they are in support of the DREAM Act by comparing null plots and the observed plot.\nUnder the null, the proportions between ideologies in support of the DREAM Act are equal . So, when we compare the null plots and observed plot, we are checking to see if our observed plot differs from the null plots. If we can identify the observed plot from the null plots, then this gives us evidence to reject the null, and believe that there is a relationship between ideology and their support of the DREAM Act.\n\n\nSimulation\nThe data set was edited so that the rows of the ideology column only included the first letter of each of the ideologies for simplicity. They were also releveled so that Liberal was on the left, Moderate was in the middle, and Conservative was on the right.\n\n\nShow the code\ndream &lt;- dream |&gt;\n  mutate(ideology = as.character(ideology)) |&gt;\n  mutate(ideology = str_extract(ideology, \"\\\\w\")) |&gt;\n  mutate(ideology = as.factor(ideology)) |&gt;\n  mutate(ideology = fct_relevel(ideology, c(\"L\", \"M\", \"C\"))) \n\n\nHere is the “statistic” in a form of a bar graph. This is our observed plot as it uses the information provided by the data set. We can see that the proportion of ‘Yes’, shaded in blue, is greater for Liberal.\n\n\nShow the code\n#to know which panel to randomly place the plot in when comparing with the null\nset.seed(47)\nsample(c(1:20), size = 1)\n\n\n[1] 18\n\n\nShow the code\nobs_dream &lt;- dream |&gt;\n  group_by(ideology) |&gt;\n  mutate(repeated = 18)\n\nobs_dream|&gt;\n   ggplot(aes(x = ideology, fill = stance)) +\n    geom_bar(position = \"fill\") +\n   labs(x = \"Ideology\", y = \"Proportion of Responses\", title = \"Observed Plot\", fill = \"Stance\")\n\n\n\n\n\n\n\n\n\nThen I created a function that conducts a permutation test by reshuffling the ideologies, but keeping the stance the same for each row.\n\n\nShow the code\npermute &lt;- function(rep){\n  dream |&gt;\n    mutate(ideology = sample(c(\"L\", \"M\", \"C\"), size = 910, replace = TRUE)) |&gt;\n    mutate(ideology = fct_relevel(ideology, c(\"L\", \"M\", \"C\"))) |&gt;\n    mutate(repeated = rep)\n}\n\n\nHere I mapped out 19 data frames (leaving out 18 because that’s reserved for the observed) that outputs what we’d expect under the null, or if the likelihood of each ideology to have a certain stance is equal.\n\n\nShow the code\n#under the null\nset.seed(47)\nnull_dream_one &lt;- map((1:17), permute)|&gt;\n    list_rbind() \n\nnull_dream_two &lt;- map((19:20), permute) |&gt;\n  list_rbind() \n\n\nFinally, I combined all the data frames (the statistic and the 19 null data frames) and combined all of the bar graphs from the 20 data frames. In the very beginning, I used a sample to generate a number so that I know which panel to place the observed plot in. Through that, the observed plot was placed in Panel #18.\n\n\nShow the code\n#to plot all the graphs\nrbind(obs_dream, null_dream_one, null_dream_two) |&gt;\n  ggplot(aes(x = ideology, fill = stance)) +\n  geom_bar(position = \"fill\") +\n  facet_wrap(~repeated) +\n  labs(x = \"Ideology\", y = \"Proportion of Responses\", title = \"Comparison of Null Plots vs. Observed Plot\", fill = \"Stance\")\n\n\n\n\n\n\n\n\n\nAs we can see from the figure above, most of the shading of blue (which is what we’re interested in as it shows the proportion of “Yes”) is almost leveled, except for Panel #18. So, the observed plot (Panel #18) does stand out from the rest of the bar graphs as the shading of blue for “L” is greater compared to the others. This figure provides evidence to reject the null hypothesis, which hypothesized that the proportion of “Yes” is equal among the ideologies.\n\n\nSummary of Simulation\nI began this study by observing the data set and noticing that there is a greater proportion of Liberals who are in support of the DREAM Act. I tested this hypothesis by shuffling the order of the ideologies, via my permute function, to see if it was common to get the order of ideologies of the original data set. To compare the observation from the 19 reshuffles, I plotted their bar graphs and checked to see if the observed bar graph was identifiable among the bar graphs of the permuted data frames, and it was. So, we have reason to believe that there is a greater proportion of Liberals in support of the DREAM Act when compared to Moderates and Conservatives.",
    "crumbs": [
      "A Simulation Study"
    ]
  },
  {
    "objectID": "miniproj_4.html",
    "href": "miniproj_4.html",
    "title": "SQL",
    "section": "",
    "text": "About the Database\nThe link to database\nUsing SQL, I queried the Wideband Acoustic Immittance (WAI) Database hosted by Smith College. WAI measurements are made to hopefully provide noninvasive auditory diagnostic tools for everyone. The WAI database hosts WAI measures on ears from all ages(infants, NICU infant, child, adults).\n\n\nShow the code\nlibrary(tidyverse)\n\n\n\n\nShow the code\nlibrary(RMariaDB)\nlibrary(dplyr)\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n\n# collect(Measurements)\n\n\n\n\nDuplicating Figures\nFor this analysis, I duplicated figure 1 that’s in “An online wideband acoustic immittance (WAI) database and corresponding website” (Voss 2020). The figure shows a line graph of frequency versus mean absorption of the 12 studies found in WAI database as of July 1, 2019. Its legend contains the authors, year, number of individual ears, and equipment used.\n\n\nShow the code\nSELECT Frequency, Identifier, LOG10(Frequency) AS scaled_freq, AVG(Absorbance) AS avg_absorb\nFROM Measurements\nWHERE Identifier IN (\"Abur_2014\", \"Feeney_2017\", \"Groon_2015\", \"Lewis_2015\", \"Liu_2008\", \"Rosowski_2012\", \"Shahnaz_2006\", \"Shaver_2013\", \"Sun_2016\", \"Voss_1994\", \"Voss_2010\", \"Werner_2010\") AND Frequency &gt; 200 AND Frequency &lt; 8000\nGROUP BY Identifier, Frequency\n\n\n\n\nShow the code\nSELECT p.Identifier, p.AuthorsShortList, p.Year, COUNT(DISTINCT SubjectNumber, Ear) AS distinct_ears\nFROM PI_Info AS p\nLEFT JOIN Measurements AS m ON m.Identifier = p.Identifier\nWHERE p.Identifier IN (\"Abur_2014\", \"Feeney_2017\", \"Groon_2015\", \"Lewis_2015\", \"Liu_2008\", \"Rosowski_2012\", \"Shahnaz_2006\", \"Shaver_2013\", \"Sun_2016\", \"Voss_1994\", \"Voss_2010\", \"Werner_2010\") AND Frequency &gt; 200 AND Frequency &lt; 8000\nGROUP BY Identifier, Instrument;\n\n\n\n\nShow the code\nSELECT p.Identifier, p.AuthorsShortList, p.Year, AVG(Absorbance) AS avg_absorb, m.Frequency, LOG10(Frequency) AS scaled_freq, CONCAT(p.AuthorsShortList, \"(\", p.Year, \") N =\", COUNT(DISTINCT SubjectNumber, Ear), \"; \", Instrument) AS key_info\nFROM PI_Info AS p\nLEFT JOIN Measurements AS m ON p.Identifier = m.Identifier\nWHERE p.Identifier IN (\"Abur_2014\", \"Feeney_2017\", \"Groon_2015\", \"Lewis_2015\", \"Liu_2008\", \"Rosowski_2012\", \"Shahnaz_2006\", \"Shaver_2013\", \"Sun_2016\", \"Voss_1994\", \"Voss_2010\", \"Werner_2010\") AND m.Frequency &gt; 200 AND m.Frequency &lt; 8000 \nGROUP BY Identifier, Instrument, Frequency\nHAVING avg_absorb &gt; 0;\n\n\n\n\nShow the code\nstrings |&gt;\n  group_by(Identifier) |&gt;\n  ggplot(aes(x = Frequency, y = avg_absorb, color = key_info)) +\n  geom_line() +\n  ylim(0, 1) +\n  xlim(200, 8000) +\n  labs(x = \"Frequency (Hz)\",\n       y = \"Mean Abosrbance\",\n       title = \"Mean absorbance from each publication in WAI database\",\n       color = \"\") +\n  theme_bw() +\n  scale_x_log10() \n\n\n\n\n\n\n\n\n\nLink to the figure I’m duplicating\nTo duplicate the figure using SQL, I first had to pull ‘Measurements’ since the table had the absorbance, frequency, and instrument. Through Measurements, I created a table with columns that include the frequency and average absorbance since those are the two main variables being compared in the graph. Because I needed the author names and years of each study, I needed to pull ‘PI_Info’. Since all the information I needed are still split into two tables, I used JOIN, and joined ‘Measurements’ and ‘PI_Info’ through ‘Identifier’ (since they both had that as a column) to combine the columns I needed and create a table with all the information needed. Once I had the table, I used ggplot to produce a figure that’s similar to Figure 1 from Voss 2020. If we compare them, we can see that the graphs are very similar.\n\n\nAnalysis of Individual Study\nI chose one of the 12 studies that included different races, sex, and ethnicity. A limitation present in this database is that many of the studies don’t have participants of different races, sex, or ethnicity. However, after taking the time to look at each study, I found that the study (Shaver 2013) included different races, sex, and ethnicity. So, this analysis will compare the frequency versus mean absorption across different races from the study (Shaver 2013).\n\n\nShow the code\nSELECT Frequency, Identifier, LOG10(Frequency) AS scaled_freq, AVG(Absorbance) AS average_absorb\nFROM Measurements\nWHERE Identifier IN (\"Shaver_2013\")\nGROUP BY Identifier, Frequency\n\n\n\n\nShow the code\nSELECT s.Identifier, s.Race, AVG(Absorbance) AS average_absorb, m.Frequency, LOG10(Frequency) AS scaled_freq\nFROM Subjects AS s\nLEFT JOIN Measurements AS m ON m.Identifier = s.Identifier\nWHERE s.Identifier IN (\"Shaver_2013\")\nGROUP BY Identifier, Frequency, Race\n\n\n\n\nShow the code\nplot2 |&gt;\n  ggplot(aes(x = Frequency, y = average_absorb)) +\n  geom_line() +\n  facet_wrap(~Race) +\n  labs(title = \"Frequency Versus Mean Absorption Across Different Races\",\n       x = \"Frequency (Hz)\",\n       y = \"Mean Absorption\")\n\n\n\n\n\n\n\n\n\nFor this analysis, I used a similar process as the one I used to duplicate Figure 1 (Voss 2020). I used SQL to pull ‘Measurements’ because it has the data for frequency and absorption. Then I had to pull ‘Subjects’ because it has the data for different races, sex, and ethnicity. To combine the needed information from both tables, I joined Measurements and Subjects through ‘Identifier’ and created a new table with just the author (Shaver), frequency, average absorption, race, sex, and ethnicity. Using the new table and ggplot, I created line graphs based on the race.\nAs seen from the plot above, all of the races included in the study have the same line. This might be because of how the study was conducted and how they counted the ears and measured the absorption. But if we simply focus on the different graphs, across the the different races, the average absorption seems to increase when frequency goes up to 3000 Hz but starts to decrease after that.",
    "crumbs": [
      "SQL"
    ]
  }
]